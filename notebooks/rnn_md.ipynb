{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.nn import Linear, LSTM, Tanh, ReLU, Module, MSELoss\n",
    "from torchvision import transforms\n",
    "from pprint import pprint\n",
    "\n",
    "from src.speech_classification.audio_processing import AudioPreprocessor\n",
    "from src.speech_classification.pytorch_conv_lstm import LstmNet\n",
    "from src.reinforcement.model_dynamics.rnn_md import LstmModelDynamics\n",
    "from src.VTL.utils import random_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load config and specify model dynamics net checkpoint to load from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('rnn_md_config.json') as data_file:\n",
    "    params = json.load(data_file)\n",
    "md_net_fname=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)\n",
    "\n",
    "device = params['train']['device']\n",
    "\n",
    "# 1. Init audio preprocessing\n",
    "preproc = AudioPreprocessor(**params['preprocessing_params'])\n",
    "sr = params['preprocessing_params']['sample_rate']\n",
    "\n",
    "# 2. Load preprocessing net\n",
    "preproc_net = torch.load(params['preproc_net_fname']).to(device)\n",
    "\n",
    "# 3. Init model dynamics net\n",
    "md_net = torch.load(md_net_fname).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generate sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_fname = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'JD2.speaker')\n",
    "lib_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'VocalTractLab2.dll')\n",
    "num_episodes = 10\n",
    "ep_duration = 1000\n",
    "timestep = 20\n",
    "num_steps_per_ep = ep_duration // timestep\n",
    "\n",
    "env = VTLEnv(lib_path, speaker_fname, timestep, max_episode_duration=ep_duration)\n",
    "\n",
    "soundnames = ['a', 'i', 'o', 'u']\n",
    "initial_states = [env.get_cf(s) for s in soundnames]\n",
    "audios, states, actions = random_rollout(env, ep_duration, timestep, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Predict and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
