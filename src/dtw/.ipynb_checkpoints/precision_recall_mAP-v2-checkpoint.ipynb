{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Study\\SpeechAcquisitionModel\\src\\dtw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(r'C:\\Study\\SpeechAcquisitionModel')\n",
    "print(os.getcwd())\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, minkowski\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "import random\n",
    "import scipy\n",
    "import torch\n",
    "\n",
    "import dtw\n",
    "import dtwalign\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "from src.speech_classification.audio_processing import SpeechCommandsDataCollector, AudioPreprocessorMFCCDeltaDelta\n",
    "from src.siamese_net_sound_similarity.slstm_train import SiameseSpeechCommandsDataCollector\n",
    "from src.siamese_net_sound_similarity.train_v2 import SiameseDeepLSTMNet\n",
    "from src.siamese_net_sound_similarity.train import SiameseLSTMNet\n",
    "\n",
    "from src.siamese_net_sound_similarity.soft_dtw import SoftDTW\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(font_scale=1.4, rc={'text.usetex' : False})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE='euclidean'\n",
    "STEP_PATTERN = 'typeIc'\n",
    "CLOSED_END_STEP_PATTERN = \"typeIc\"\n",
    "# DISTANCE=lambda x, y : minkowski(x,y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_words = ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left',\n",
    "                'marvin',\n",
    "                'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two',\n",
    "                'up', 'wow', 'yes', 'zero']\n",
    "\n",
    "wanted_words_combined = wanted_words\n",
    "\n",
    "model_settings = {\n",
    "    'dct_coefficient_count': 13,\n",
    "    'mfcc_num': 39,\n",
    "    'label_count': len(wanted_words_combined) + 2,\n",
    "    'hidden_reccurent_cells_count': 128,\n",
    "    'winlen': 0.02,\n",
    "    'winstep': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = AudioPreprocessorMFCCDeltaDelta(numcep=model_settings['dct_coefficient_count'], winlen=model_settings['winlen'],\n",
    "                                     winstep=model_settings['winstep'])\n",
    "\n",
    "data_iter = SiameseSpeechCommandsDataCollector(preproc,\n",
    "                                        data_dir=r'C:\\Study\\Speech_command_classification\\speech_dataset',\n",
    "                                        wanted_words=wanted_words_combined,\n",
    "                                        testing_percentage=10,\n",
    "                                        validation_percentage=10\n",
    "                                        )\n",
    "\n",
    "index_to_word = {v:k for k,v in data_iter.word_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False  True False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False  True False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False  True False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False]\n",
      "[17. 23.  9.  4. 11. 28. 10.  2. 28. 12. 12. 13. 22.  7.  4. 25. 23. 10.\n",
      " 18. 12. 29.  4.  6. 31. 30. 16. 12.  9. 10.  7.  8. 13.  9. 24.  9. 20.\n",
      "  7. 17. 25. 26. 20. 10. 17. 12. 25. 21.  6. 23. 18. 11. 27.  8. 24.  8.\n",
      " 26. 16.  6. 25. 10. 28. 23. 25. 20. 31. 11.  2.  7.  8. 28. 18.  3. 18.\n",
      "  5. 12. 14. 25. 12. 18. 28. 14. 16. 20. 14. 23. 28. 20.  7. 17. 10. 20.\n",
      " 30.  3. 15. 31. 10. 27. 27. 13.  2. 26. 10.  5. 10. 12.  5. 25. 30. 11.\n",
      "  4. 27. 17.  8. 20.  3. 15. 13. 13. 21. 28. 18. 21.  2. 16.  9. 17.  9.\n",
      " 13.  6. 15. 15. 16.  4.  5. 16.  2.  8. 14. 25.  3.  7. 28. 19.  2. 13.\n",
      " 11. 27.  7. 13. 20. 20.  7. 17. 18. 31. 11. 15.  7. 15. 18. 18.  9.  7.\n",
      " 27. 19. 25.  3. 17. 26. 22. 25.  9. 15.  6. 28.  5. 21. 12. 29. 19. 27.\n",
      " 17. 28.  2. 17. 21. 11.  6. 31. 21. 24. 10. 10.  8. 17. 10. 10.  2. 31.\n",
      " 22. 25. 11. 30. 18. 23.  4. 24. 21. 30. 17. 17.  9. 13. 16. 26. 25. 21.\n",
      " 27.  9. 24. 28.  4. 26. 26. 12. 28. 20. 28. 20. 17. 20.  7. 27.  9. 27.\n",
      "  6. 29. 19. 27. 17. 25.  4. 20. 23. 28. 23. 29. 17. 18. 28.  2. 25. 13.\n",
      " 28. 25. 11. 16. 21. 20.  7. 17. 21. 27. 23.  6. 31. 13. 22. 11. 24. 11.\n",
      "  6.  9. 18.  6. 19. 13. 27. 23.  4.  9. 19. 21. 14.  2. 23. 27. 22. 25.\n",
      " 27. 20. 16. 19. 26. 21. 17. 29. 11. 30.  9. 13. 31. 27. 15.  3.  4.  3.\n",
      " 17.  7. 21. 18. 15. 12. 13. 15.  2. 11. 16. 18. 25.  4. 17. 20. 17. 30.\n",
      " 27.  8. 10. 20. 23. 13. 28. 25.  8. 28. 14. 17. 24. 27. 10. 28.  9.  9.\n",
      "  8. 29. 28. 13.  8.  9. 25.  3. 18. 20. 14. 21. 31. 18. 31. 14. 16. 11.\n",
      "  6. 28. 14. 15. 11. 31. 20. 28. 23. 21. 15.  5. 20.  9.  8.  8. 17.  8.\n",
      " 31. 30. 27. 25.  4. 31.  7. 31. 29. 21. 11.  6. 20.  9.  6. 10. 16. 27.\n",
      " 10.  5. 12. 21. 12. 28. 31. 11. 16.  9. 31. 10. 20. 17. 22. 17.  2. 10.\n",
      " 18. 18. 24. 31.  3. 15. 14. 11. 30.  5. 15. 16. 10. 16. 13.  5. 25. 24.\n",
      " 13. 19. 11.  7. 27. 25. 10. 24. 24. 31. 25.  6. 17. 23. 30.  4.  7.  2.\n",
      " 18. 24. 10. 20. 17.  6. 11. 26.  6. 19. 31. 16.  3. 31. 26. 15.  2.  3.\n",
      " 17. 10. 15.  2.  9.  6.  2. 22. 26. 13. 11. 28. 15. 30. 25. 12. 26.  9.\n",
      " 23.  4. 25. 10. 17.  8. 16. 26. 25. 25.  5. 20. 27. 11.  4. 30. 18. 16.\n",
      " 15.  5. 22. 16.  2. 13. 18. 13. 30.  5. 26.  9. 28. 10. 23. 31. 28.  7.\n",
      "  9. 28. 27. 31. 21.  7. 16. 31. 19. 31. 17.  2. 23. 23.  8.  6. 28. 25.\n",
      "  5. 25. 10. 16. 18.  6.  9. 21. 17. 25. 19. 30.  4.  6. 16. 31.  2. 16.\n",
      " 13. 18. 20. 24. 24.  7. 13. 26. 27. 18. 14.  6.  5.  9.  8. 14. 30.  9.\n",
      " 16. 19. 24. 30.  9. 26. 27. 31. 15. 16.  8. 22. 26. 15. 17.  8.  7. 17.\n",
      " 24. 29. 12. 11. 23. 18. 21.  7.  2. 18. 19. 30. 23. 12.  2.  3.  4.  5.\n",
      "  3. 26. 21. 28. 28.  2.  5. 21.  3. 23. 23. 10. 18. 31. 27. 11.  3. 21.\n",
      " 17. 13. 10.  9. 12.  5. 15.  5. 20. 18.  7. 15.  7.  9. 13.  9.  3.  5.\n",
      " 17. 24. 13.  5. 11. 16. 18. 18.  6.  4. 19. 31. 27. 15. 25. 20. 15. 15.\n",
      " 15.  6. 23.  3. 24. 17. 15. 28. 10. 31. 14.  3. 10.  3.  8. 11. 28. 24.\n",
      " 29. 14. 12. 14.  5. 17.  8. 11. 18. 18. 31. 23. 22. 31. 25. 13. 23. 12.\n",
      "  5. 26. 22. 18. 22. 13. 30. 21. 23. 17. 15. 16. 24. 14. 16. 19. 31. 17.\n",
      " 10. 27. 16. 20. 24. 10.  8. 18. 31. 30. 31. 24. 28. 20. 25. 10. 13. 30.\n",
      "  8. 12. 17.  9. 21. 19. 29. 30.  3.  3. 28. 27. 26.  7. 18. 19. 27. 30.\n",
      " 16. 25. 13.  2. 30. 19. 22.  3. 15. 28.  5. 13. 31. 29. 28.  8. 11. 11.\n",
      " 16. 15. 30. 25. 20. 18. 23. 30. 31. 23. 30. 17. 10. 18. 31. 24. 14. 10.\n",
      " 31.  2. 11. 25. 13. 27. 27. 22.  2. 25. 21.  5. 10. 27.  7. 10. 31. 19.\n",
      "  6. 13. 29. 27.  2. 11. 12. 26. 27. 19. 15. 23.  9. 13.  2.  8. 17.  6.\n",
      " 31. 22.  5.  9. 16. 13. 31.  8. 22.  6. 13. 12. 26.  6.  3. 29. 30.  3.\n",
      " 14. 24. 24. 15. 28. 23. 16.  7. 19. 25.  9.  5. 18. 25. 23. 25. 22. 21.\n",
      " 30. 28.  3. 20.  3. 12.  7. 17. 20.  7.  5. 15.  7. 27. 20.  9. 23. 19.\n",
      " 13. 28.  2.  7.  5.  7. 20. 28. 25. 26. 12. 16. 31. 28.  2.  4. 25.  4.\n",
      "  7.  5. 12. 18. 31. 27. 25.  6.  2. 21.  4. 11.  2. 16. 19.  2. 14. 11.\n",
      " 31.  2. 14. 31. 30. 27.  6. 12.  9. 21. 10. 11. 29. 11. 18. 20.  4. 20.\n",
      " 14. 27. 24. 24.  8. 19.  3.  9. 16. 26. 29. 31. 29. 21.  6.  8.  6.  5.\n",
      "  5. 18. 30. 23. 10. 21. 25. 28. 19. 16. 13. 24. 24.  2. 30.  9.  6. 17.\n",
      " 24. 11. 13. 19.  9. 19. 16.  5.  5. 23.  2. 20. 18. 22.  8. 25. 19. 14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30. 10. 19.  5. 22. 27. 30.  7. 26. 11.]\n",
      "[ 3. 23. 19. 13. 24. 10. 30. 20.  3.  2. 30.  6. 31.  9. 25. 26. 19. 11.\n",
      " 27. 13.  9. 31. 31. 25.  5. 24. 14. 12. 25. 15. 24.  2. 21.  9. 13. 31.\n",
      " 10. 29. 25. 31. 19.  5. 12. 24. 13. 17. 31. 18. 17.  9. 25. 13. 31.  5.\n",
      " 24. 23. 10. 17.  9.  7. 10. 31. 26. 15. 17.  5.  6.  8. 12.  6. 28. 12.\n",
      " 21. 18. 25.  9. 30. 25. 30. 21. 20. 31.  9. 25. 21. 31. 13.  2. 10. 28.\n",
      " 28. 21. 31. 14. 18. 10. 24. 30. 10. 10. 10.  5.  7. 25. 21.  5. 17.  2.\n",
      " 31. 13. 30. 22. 24. 12.  3. 15. 10.  9. 21. 14. 18.  3. 28. 12. 10. 25.\n",
      " 10. 13.  2. 22. 20.  5. 10. 27. 14. 27. 25. 15. 29.  2.  8.  3. 20. 17.\n",
      " 15.  5.  8. 26. 11. 24. 26. 13.  2. 10. 18.  9. 25.  7. 11. 12.  5.  3.\n",
      " 10.  6.  3. 24. 24. 20. 30.  3. 28. 10. 10. 17. 14.  7. 16. 29. 26. 28.\n",
      "  6. 27. 17. 16.  2.  4. 25. 24. 25. 17. 13. 22.  2. 11.  3. 12. 12. 18.\n",
      " 26. 10.  5.  2. 27. 19. 15. 24. 25. 25. 17. 15. 21. 28. 14. 22. 20.  2.\n",
      " 20.  9. 11. 14. 31. 30. 10. 18.  3. 26. 26. 18. 31. 17. 17. 31. 15. 24.\n",
      " 16. 26. 23. 30. 26.  9. 28. 12.  3. 19.  2. 17.  3. 24. 21. 27.  9. 16.\n",
      " 25.  6. 22. 20. 16. 27.  6. 28.  7. 11.  3. 25. 10. 23. 27. 21. 20. 19.\n",
      "  7. 25. 15.  9.  3. 21. 30. 14. 24. 12.  5. 23. 28. 29.  3. 28. 10. 10.\n",
      " 11. 17.  9. 31. 25.  2. 16.  5. 11. 21. 14.  5. 14. 29. 23. 20. 28. 18.\n",
      " 11. 10. 30. 24. 22. 24. 13. 30. 31. 22. 11. 26. 18. 28. 10.  4. 16. 15.\n",
      " 17.  4. 14. 17. 11. 20. 11. 21.  2. 12. 23. 23.  5. 18. 24. 28. 13. 31.\n",
      " 23.  2. 20. 11. 10.  8.  3. 23. 27. 31. 20. 20. 18. 14. 31. 29. 29. 19.\n",
      " 31. 25. 13. 13. 21. 19. 17. 12. 22. 20.  8.  4.  8.  9. 19.  7. 23. 11.\n",
      " 10. 12. 19. 16. 28. 20. 15. 14. 14. 30. 27.  5.  6. 12.  9. 30. 23. 16.\n",
      " 16. 20. 30. 31. 28. 23. 14. 16. 19. 21.  9. 19. 27. 27. 27. 17.  7. 30.\n",
      " 17. 27.  2. 16. 16. 31.  6.  5. 27. 11. 24. 14.  8.  2. 14. 24. 27.  7.\n",
      "  4. 28. 30.  4. 16. 24.  7. 31. 12. 10. 12. 23. 18.  9. 19. 20. 11.  5.\n",
      "  7. 21. 31. 27. 21. 12. 25. 14. 23. 30. 28. 20.  4.  3. 14. 30. 26.  2.\n",
      " 26. 31. 24. 13. 16. 29. 15. 12. 27. 19. 13.  7.  8. 13. 30.  7. 10. 30.\n",
      " 20. 11. 17. 23. 21. 21. 31. 20.  2. 20. 10. 25. 17. 15. 21.  5.  9. 13.\n",
      " 11. 25. 13. 15.  9.  5. 10.  7. 17. 28. 25. 17. 29.  5.  4. 19. 28. 14.\n",
      " 18.  3. 16. 31. 25. 24. 12. 12. 10. 17. 17. 25. 27. 31. 20. 13. 27. 16.\n",
      " 29. 30.  9. 31. 17. 12. 12.  6. 16.  9. 19. 18. 25. 21.  6. 11. 17. 17.\n",
      " 19. 19. 16.  5. 25. 19. 12.  8. 14. 27. 18. 11.  5. 31. 25. 17. 24. 11.\n",
      " 26. 29.  8. 25. 22. 24. 21. 11. 24. 26. 28. 27. 18. 31. 26. 26. 17. 27.\n",
      " 31.  5. 22. 30.  6.  8. 17. 24.  8. 19.  9. 26.  2. 18. 30. 20.  4. 28.\n",
      " 19. 30. 13. 14. 17.  3.  6. 28.  6. 28. 11. 11. 27. 21.  9. 22.  6. 16.\n",
      " 16. 11. 18. 19.  9. 13. 10. 16.  3. 24. 19. 16. 23. 23. 12. 17. 12.  6.\n",
      " 31. 10.  2. 23. 28. 25. 30. 24. 27.  9.  4. 24.  4. 15. 18. 10. 28.  5.\n",
      "  2.  6. 16.  2. 23. 30.  2. 23.  5. 10.  5. 26. 25. 23.  4. 19. 25.  8.\n",
      "  8. 28.  4. 25. 13. 24. 21. 12. 22. 16. 31.  9.  8.  7.  7. 16. 29. 21.\n",
      "  5. 25. 28. 17. 18. 28. 26. 21. 17. 10. 20.  9.  3. 13. 22.  8.  6.  8.\n",
      " 12.  6.  6.  3. 28. 28.  3. 24. 27. 18. 31. 29. 10. 18.  3.  4.  3. 21.\n",
      " 24.  9. 14. 24. 16. 23. 20.  2. 18. 14. 24. 17. 12. 26. 30. 17. 15. 29.\n",
      "  5.  5. 28. 24. 31. 25. 22. 17. 19.  9. 19. 25. 12.  3. 16. 31. 18.  8.\n",
      " 26. 11. 10. 17. 18. 24. 16.  6. 24. 17.  7. 25. 18. 10. 21. 25. 17. 13.\n",
      " 10. 27. 30.  6. 29. 22. 10.  2. 22. 16. 30. 10. 30. 17. 31. 29.  9.  8.\n",
      " 31. 25. 10.  6. 31. 28. 20. 27. 26. 29. 16.  2.  8. 21.  9.  4. 21. 20.\n",
      " 10. 19. 24. 10. 12. 19.  8. 10. 12. 13.  9. 16. 27. 10. 16. 27. 28. 21.\n",
      " 10. 31. 16.  9. 18. 28.  5. 19.  7.  5. 25. 23. 27.  6. 26. 14. 19. 18.\n",
      "  2.  5.  8. 11. 25.  9. 28. 28.  6. 13. 23. 21. 21. 19. 22. 26. 21. 17.\n",
      " 11. 13. 12. 18.  4. 13. 19. 21.  2.  7.  6. 18.  5.  9. 26. 19. 25. 21.\n",
      " 24.  4. 26. 24. 10. 16. 24. 13. 27. 23. 17. 29.  3. 11. 27. 27. 14. 15.\n",
      " 17. 31. 15. 21.  5.  4. 14. 10. 24. 23. 20. 30. 23. 13. 30. 26.  2. 12.\n",
      " 24. 16.  7. 14.  9. 19. 14. 10. 19. 10. 19.  9. 19.  5.  5. 17. 16. 31.\n",
      "  2. 31.  4. 21. 17. 19. 17. 30.  3.  6. 11. 28.  8. 10. 30. 21.  4. 26.\n",
      " 19.  6. 11. 30.  2. 13. 13. 20.  4. 30.  6.  8.  5. 10. 16. 22.  9. 12.\n",
      " 23.  6.  5. 25. 11. 17. 25. 18. 26. 28.]\n",
      "34\n",
      "(1000, 99, 39)\n"
     ]
    }
   ],
   "source": [
    "n_mini_batch_size = 4000\n",
    "\n",
    "# gather data\n",
    "\n",
    "\n",
    "data = data_iter.get_data(n_mini_batch_size, 0, 'validation')\n",
    "labels = data['y']\n",
    "\n",
    "data1 = data_iter.get_data(n_mini_batch_size, 0, 'validation')\n",
    "labels1 = data1['y']\n",
    "idx = np.random.randint(0, len(labels1), len(labels1))\n",
    "data1_x = data1['x'][idx]\n",
    "data1['x'] = data1_x\n",
    "labels1 =  np.array(data1['y'])[idx]\n",
    "data1['y'] = labels1\n",
    "\n",
    "# labesl1 = data1['y']\n",
    "\n",
    "# duplicates = data_iter.get_duplicates(labels, 0, 'testing')\n",
    "# assert np.any(labels == duplicates['y'])\n",
    "# duplicates['x'] = duplicates['x'][:n_duplicates_size]\n",
    "# print(duplicates['x'].shape)\n",
    "\n",
    "# non_duplicates = data_iter.get_nonduplicates(labels, 0, 'testing')\n",
    "# assert np.any(labels != non_duplicates['y'])\n",
    "\n",
    "# y_true = np.concatenate((np.ones((n_duplicates_size)), np.zeros((n_mini_batch_size))))\n",
    "y_true = labels==labels1\n",
    "print(y_true)\n",
    "print(labels)\n",
    "print(labels1)\n",
    "print(sum(y_true))\n",
    "print(data['x'].shape)\n",
    "dists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MFCC Precision/Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize dist_lists\n",
    "\n",
    "dtw = []\n",
    "\n",
    "for i in range(n_mini_batch_size):\n",
    "    print(i, end='\\r')\n",
    "    x = data['x'][i].squeeze()\n",
    "    y = data1['x'][i].squeeze()\n",
    "    dtw.append(dtwalign.dtw(x, y, dist=DISTANCE, step_pattern=STEP_PATTERN, open_end=False, dist_only=True).normalized_distance)\n",
    "\n",
    "mfcc_dtw_dist = np.array(dtw)\n",
    "dists.append(mfcc_dtw_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Improving DTW using latent variables from LSTM classifier as a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nn\n",
    "\n",
    "nn_ce = r'C:\\Study\\SpeechAcquisitionModel\\reports\\seamise_net_10_27_2019_04_37_PM\\net_0.5.net'\n",
    "nn_ce_l2 = r'C:\\Study\\SpeechAcquisitionModel\\reports\\seamise_net_10_27_2019_02_19_PM\\net_0.40625.net'\n",
    "nn_ce_dtw = r'C:\\Study\\SpeechAcquisitionModel\\reports\\seamise_net_10_25_2019_01_55_PM\\net_0.4609375.net'\n",
    "\n",
    "nn_fnames = [nn_ce, nn_ce_l2, nn_ce_dtw]\n",
    "model_names = ['MFCC', 'CE', 'CE+L2-triplet', 'CE+DTW-triplet']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - SOFT-DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################\n",
      "# Model CE\n",
      "############################################################################\n",
      "############################################################################\n",
      "# PREFIX LENGTH : 100\n",
      "############################################################################\n",
      "############################################################################\n",
      "# Model CE+L2-triplet\n",
      "############################################################################\n",
      "############################################################################\n",
      "# PREFIX LENGTH : 100\n",
      "############################################################################\n",
      "############################################################################\n",
      "# Model CE+DTW-triplet\n",
      "############################################################################\n",
      "############################################################################\n",
      "# PREFIX LENGTH : 100\n",
      "############################################################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(len(nn_fnames)):\n",
    "    nn_fname = nn_fnames[i]\n",
    "    nn = torch.load(nn_fname).cpu()\n",
    "    nn.eval()\n",
    "\n",
    "    print(f\"############################################################################\\n\\\n",
    "# Model {model_names[i+1]}\\n\\\n",
    "############################################################################\")\n",
    "\n",
    "    PREFIX_LENS = [100]\n",
    "\n",
    "    for PREFIX_LEN in PREFIX_LENS:\n",
    "        print(f\"############################################################################\\n\\\n",
    "# PREFIX LENGTH : {PREFIX_LEN}\\n\\\n",
    "############################################################################\")\n",
    "        nn_input = torch.from_numpy(data['x'][:, :PREFIX_LEN, :]).float()\n",
    "\n",
    "\n",
    "        z, *_ = nn.single_forward(nn_input)\n",
    "        z = z\n",
    "\n",
    "        z1, *_ = nn.single_forward(torch.from_numpy(data1['x']).float())\n",
    "        z1 = z1\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "        # DTW\n",
    "        ###########################################################################\n",
    "\n",
    "        soft_dtw_loss_open_end = SoftDTW(open_end=True, dist='l1')\n",
    "        soft_dtw_loss_close_end = SoftDTW(open_end=False, dist='l1')\n",
    "\n",
    "        ##########################################################################\n",
    "        # OPEN END = False\n",
    "        ##########################################################################\n",
    "\n",
    "        # initialize dist_lists\n",
    "\n",
    "        dtw_z = []\n",
    "\n",
    "        for i in range(n_mini_batch_size):\n",
    "            print(i, end='\\r')\n",
    "            x = z[i].squeeze()\n",
    "            y = z1[i].squeeze()\n",
    "\n",
    "            d = soft_dtw_loss_close_end(x, y)\n",
    "            dtw_z.append(d.detach().cpu().numpy())\n",
    "\n",
    "        dtw_dist = np.array(dtw_z)\n",
    "        dists.append(dtw_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Precision_Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# no skill model\n",
    "precision, recall, _ = precision_recall_curve(y_true, np.zeros(len(y_true)), pos_label=1)\n",
    "ax = sns.lineplot(recall, precision)\n",
    "ax.lines[0].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, -dists[i], pos_label=1)\n",
    "    sns.lineplot(recall, precision, label=model_names[i], linewidth=3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Average Precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_names)):\n",
    "    average_precision = average_precision_score(y_true, -dists[i])\n",
    "    print(model_names[i], average_precision)\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, models_dists[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
