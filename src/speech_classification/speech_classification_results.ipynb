{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from src.speech_classification.audio_processing import AudioPreprocessorFbank, SpeechCommandsDataCollector\n",
    "from src.speech_classification.pytorch_conv_lstm import LstmNet\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4581186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wanted_words = ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin',\n",
    "                'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two',\n",
    "                'up', 'wow', 'yes', 'zero']\n",
    "wanted_words_tanh_transition = ['a_a', 'a_i', 'a_u', 'a_o', 'a_e',\n",
    "                                'i_a', 'i_i', 'i_u', 'i_o', 'i_e',\n",
    "                                'u_a', 'u_i', 'u_u', 'u_o', 'u_e',\n",
    "                                'o_a', 'o_i', 'o_u', 'o_o', 'o_e',\n",
    "                                'e_a', 'e_i', 'e_u', 'e_o', 'e_e']\n",
    "\n",
    "wanted_words_combined = wanted_words_tanh_transition\n",
    "\n",
    "\n",
    "model_settings = {\n",
    "    'dct_coefficient_count': 26,\n",
    "    'label_count': len(wanted_words_combined) + 2,\n",
    "    'hidden_reccurent_cells_count': 64,\n",
    "    'winlen': 0.04,\n",
    "    'winstep': 0.04\n",
    "}\n",
    "\n",
    "save_dir = r'C:\\Study\\SpeechAcquisitionModel\\models\\speech_classification'\n",
    "if not os.path.exists(save_dir):\n",
    "    try:\n",
    "        os.makedirs(save_dir)\n",
    "    except:\n",
    "        pass\n",
    "best_acc = 0.0\n",
    "lowest_loss = 100.0\n",
    "data_dir=r'C:\\Study\\SpeechAcquisitionModel\\data\\raw\\Simple_transitions\\02_25_2019_03_29_PM_08'\n",
    "\n",
    "preproc = AudioPreprocessorFbank(model_settings['dct_coefficient_count'], winlen=model_settings['winlen'], winstep=model_settings['winstep'])\n",
    "data_iter = SpeechCommandsDataCollector(preproc,\n",
    "                                        data_dir=data_dir,\n",
    "                                        wanted_words=wanted_words_combined,\n",
    "                                        testing_percentage=10,\n",
    "                                        validation_percentage=10\n",
    "                                        )\n",
    "\n",
    "net_fname = r\"C:\\Study\\SpeechAcquisitionModel\\models\\speech_classification\\simple_lstm_04_03_2019_04_30_PM_acc_0.8867.pt\"\n",
    "\n",
    "\n",
    "# Final test accuracy\n",
    "n_mini_batch_size = 100\n",
    "d = data_iter.get_data(n_mini_batch_size, 0, 'testing')\n",
    "data = d['x']\n",
    "labels = d['y']\n",
    "seq_lengths = d['seq_len']\n",
    "\n",
    "# load best model\n",
    "net = torch.load(net_fname)\n",
    "\n",
    "data = torch.from_numpy(data).float()\n",
    "labels = torch.from_numpy(labels).long()\n",
    "\n",
    "\n",
    "pred, hidden, _, _ = net(data, seq_lengths)\n",
    "test_loss = torch.nn.CrossEntropyLoss()(pred, labels)\n",
    "\n",
    "print(test_loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_words = ['a_i', 'a_u', 'a_o', 'u_i', 'u_a']\n",
    "n_samples_per_class = 5\n",
    "for w in selected_words:\n",
    "    fnames = [f for f in os.listdir(os.path.join(data_dir, w)) if f.endswith('.wav') ]\n",
    "    selected_fnames = [os.path.join(data_dir, w) + '/' + f for f in random.sample(fnames, n_samples_per_class)]\n",
    "    \n",
    "    plt.figure(figsize=(14,14))\n",
    "    for i, f in enumerate(selected_fnames):\n",
    "        preprocessed = preproc(f)\n",
    "        ax1 = plt.subplot(3, n_samples_per_class, i+1)\n",
    "        ax1.imshow(preprocessed.T)\n",
    "        plt.title(\"Mel-Fbank \" + os.path.basename(w))\n",
    "        \n",
    "        data = torch.from_numpy(preprocessed).float().unsqueeze(dim=0)\n",
    "        pred, hidden, out, full_pred = net(data, np.array([data.shape[1]]))\n",
    "#         print(full_pred.shape)\n",
    "        log_full_pred = torch.nn.Softmax(dim=1)(full_pred.squeeze())\n",
    "        ax2 = plt.subplot(3, n_samples_per_class, n_samples_per_class + i + 1)\n",
    "        ax2.imshow(out.detach().cpu().numpy().squeeze().T)\n",
    "        \n",
    "        plt.title(\"NN hidden \" + os.path.basename(w))\n",
    "        \n",
    "        ax3 = plt.subplot(3, n_samples_per_class, 2*n_samples_per_class + i + 1)\n",
    "        asd = ax3.imshow(log_full_pred.detach().cpu().numpy().squeeze().T, aspect='auto')\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks(np.arange(0, 26, 1))\n",
    "        ax.set_yticklabels(wanted_words_tanh_transition)\n",
    "        plt.colorbar(asd)\n",
    "        plt.title(\"NN pred \" + os.path.basename(w))\n",
    "        \n",
    "        \n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
