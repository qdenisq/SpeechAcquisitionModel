{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Study\\SpeechAcquisitionModel')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from src.speech_classification.audio_processing import AudioPreprocessorFbank, SpeechCommandsDataCollector\n",
    "from src.speech_classification.pytorch_conv_lstm import LstmNet, LstmNetEnsemble\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5736984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wanted_words = ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin',\n",
    "                'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two',\n",
    "                'up', 'wow', 'yes', 'zero']\n",
    "wanted_words_tanh_transition = ['a_a', 'a_i', 'a_u', 'a_o',\n",
    "                                'i_a', 'i_i', 'i_u', 'i_o',\n",
    "                                'u_a', 'u_i', 'u_u', 'u_o',\n",
    "                                'o_a', 'o_i', 'o_u', 'o_o' ]\n",
    "\n",
    "wanted_words_combined = wanted_words_tanh_transition\n",
    "\n",
    "\n",
    "model_settings = {\n",
    "    'dct_coefficient_count': 26,\n",
    "    'label_count': len(wanted_words_combined) + 2,\n",
    "    'hidden_reccurent_cells_count': 64,\n",
    "    'winlen': 0.04,\n",
    "    'winstep': 0.04,\n",
    "    'num_nets': 5\n",
    "}\n",
    "\n",
    "save_dir = r'C:\\Study\\SpeechAcquisitionModel\\models\\speech_classification'\n",
    "if not os.path.exists(save_dir):\n",
    "    try:\n",
    "        os.makedirs(save_dir)\n",
    "    except:\n",
    "        pass\n",
    "best_acc = 0.0\n",
    "lowest_loss = 100.0\n",
    "data_dir=r'C:\\Study\\Speech_command_classification\\speech_dataset'\n",
    "\n",
    "preproc = AudioPreprocessorFbank(model_settings['dct_coefficient_count'], winlen=model_settings['winlen'], winstep=model_settings['winstep'])\n",
    "data_iter = SpeechCommandsDataCollector(preproc,\n",
    "                                        data_dir=data_dir,\n",
    "                                        wanted_words=wanted_words_combined,\n",
    "                                        testing_percentage=10,\n",
    "                                        validation_percentage=10\n",
    "                                        )\n",
    "\n",
    "net_fname = r\"C:/Study/SpeechAcquisitionModel/models/speech_classification/simple_lstm_05_30_2019_07_12_PM_acc_0.8711.pt\"\n",
    "\n",
    "\n",
    "# Final test accuracy\n",
    "n_mini_batch_size = 100\n",
    "d = data_iter.get_data(n_mini_batch_size, 0, 'testing')\n",
    "data = d['x']\n",
    "labels = d['y']\n",
    "seq_lengths = d['seq_len']\n",
    "\n",
    "# load best model\n",
    "net = torch.load(net_fname)\n",
    "net.eval()\n",
    "data = torch.from_numpy(data).float()\n",
    "labels = torch.from_numpy(labels).long()\n",
    "\n",
    "\n",
    "pred, hidden, _, _ = net(data, seq_lengths)\n",
    "pred = torch.stack(pred).mean(dim=0)\n",
    "test_loss = torch.nn.CrossEntropyLoss()(pred, labels)\n",
    "\n",
    "print(test_loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (1, 18), got torch.Size([1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7a83246ed261>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtrue_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrue_pred_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mcross_entopry_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrue_pred_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 904\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1970\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[1;32m-> 1800\u001b[1;33m                 out_size, target.size()))\n\u001b[0m\u001b[0;32m   1801\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected target size (1, 18), got torch.Size([1])"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAACcCAYAAAAEYosxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx4XUKTwupE7hcSF1Co8LqVN4/h+yBjqy3sd76AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e73b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_words = ['a_i', 'a_u', 'a_o', 'u_a', 'u_i', 'i_a']\n",
    "# selected_words = ['a_i', 'a_u']\n",
    "\n",
    "n_samples_per_class = 5\n",
    "n_subplots = 6\n",
    "for w in selected_words:\n",
    "    fnames = [f for f in os.listdir(os.path.join(data_dir, w)) if f.endswith('.wav') ]\n",
    "    selected_fnames = [os.path.join(data_dir, w) + '/' + f for f in random.sample(fnames, n_samples_per_class)]\n",
    "    \n",
    "    plt.figure(figsize=(14,14))\n",
    "    for i, f in enumerate(selected_fnames):\n",
    "        preproc = AudioPreprocessorFbank(model_settings['dct_coefficient_count'], winlen=model_settings['winlen'], winstep=model_settings['winstep'])\n",
    "        preprocessed = preproc(f)[2:, :]\n",
    "        ax1 = plt.subplot(n_subplots, n_samples_per_class, i+1)\n",
    "        asd4 = ax1.imshow(preprocessed.T[:, 2:])\n",
    "        plt.colorbar(asd4)\n",
    "        plt.title(\"Mel-Fbank \" + os.path.basename(w))\n",
    "        \n",
    "        data = torch.tensor(torch.from_numpy(preprocessed).float().unsqueeze(dim=0), requires_grad=True)\n",
    "        pred, hidden, out, full_pred_0 = net(data, np.array([data.shape[1]]))\n",
    "#         pred = pred[0]\n",
    "#         pred_mean = pred\n",
    "        pred = torch.stack(full_pred_0)\n",
    "        pred_mean = pred.mean(dim=0)\n",
    "        pred_mean = torch.nn.Softmax(dim=-1)(pred_mean)\n",
    "#         print(pred_mean.shape)\n",
    "        true_pred_idx = wanted_words_combined.index(w) + 2\n",
    "#         print(true_pred_idx)\n",
    "        true_pred = torch.zeros(model_settings['label_count'])\n",
    "        true_pred[true_pred_idx] = 1.\n",
    "        \n",
    "        cross_entopry_loss = torch.nn.CrossEntropyLoss()(pred_mean, torch.tensor([true_pred_idx]))\n",
    "        \n",
    "        # backward\n",
    "#         grad = torch.autograd.grad(pred_mean[:, true_pred_idx], data)[0].numpy().squeeze()\n",
    "        grad = torch.autograd.grad(cross_entopry_loss, data)[0].numpy().squeeze()\n",
    "#         plt.im\n",
    "        \n",
    "#         print(grad.shape)\n",
    "        \n",
    "        full_pred_0 = torch.stack(full_pred_0)\n",
    "#         print(full_pred.shape)\n",
    "        full_pred = torch.nn.Softmax(dim=-1)(full_pred_0)\n",
    "        full_pred_std = full_pred.std(dim=0).detach().cpu().numpy().squeeze()\n",
    "#         print(full_pred.shape)\n",
    "#         print(full_pred_std.shape)\n",
    "        full_pred = full_pred.mean(dim=0).squeeze()\n",
    "#         print(full_pred.shape)\n",
    "#         print(full_pred.shape)\n",
    "        log_full_pred = torch.nn.LogSoftmax(dim=-1)(full_pred_0)\n",
    "        log_full_pred = log_full_pred.mean(dim=0).squeeze()\n",
    "        \n",
    "        entropy = -1 * (full_pred * log_full_pred).sum(dim=-1)\n",
    "        \n",
    "#         print(entropy.shape)\n",
    "\n",
    "        ax2 = plt.subplot(n_subplots, n_samples_per_class, n_samples_per_class + i + 1)\n",
    "        awsd3 = ax2.imshow(grad.T)\n",
    "        plt.colorbar(awsd3)\n",
    "\n",
    "\n",
    "        ax2 = plt.subplot(n_subplots, n_samples_per_class, 2*n_samples_per_class + i + 1)\n",
    "        ax2.plot(entropy.detach().cpu().numpy())\n",
    "#         ax2.imshow(out[0].detach().cpu().numpy().squeeze().T)\n",
    "        \n",
    "        plt.title(\"NN entropy \" + os.path.basename(w))\n",
    "        \n",
    "#         print(log_full_pred.shape)\n",
    "#         print(model_settings['label_count'])\n",
    "        \n",
    "\n",
    "        \n",
    "        ax4 = plt.subplot(n_subplots, n_samples_per_class, 3*n_samples_per_class + i + 1)\n",
    "        asd4 = ax4.imshow(full_pred.detach().cpu().numpy().squeeze().T, aspect='auto')\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks(np.arange(0, model_settings['label_count'], 1))\n",
    "        labels=['(empty)', '(empty)']\n",
    "        labels.extend(wanted_words_tanh_transition)\n",
    "        ax.set_yticklabels(labels)\n",
    "        plt.colorbar(asd4)\n",
    "        plt.title(\"NN pred \" + os.path.basename(w))\n",
    "        \n",
    "        ax5 = plt.subplot(n_subplots, n_samples_per_class, 4*n_samples_per_class + i + 1)\n",
    "        asd5 = ax5.imshow(full_pred_std.T, aspect='auto')\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks(np.arange(0,  model_settings['label_count'], 1))\n",
    "        labels=['(empty)', '(empty)']\n",
    "        labels.extend(wanted_words_tanh_transition)\n",
    "        ax.set_yticklabels(labels)\n",
    "        plt.colorbar(asd5)\n",
    "        plt.title(\"NN pred std \" + os.path.basename(w))\n",
    "        \n",
    "\n",
    "#         ax5 = plt.subplot(5, n_samples_per_class, 4*n_samples_per_class + i + 1)\n",
    "#         asd5 = ax5.imshow(full_pred_0.squeeze().mean(dim=0).detach().cpu().numpy().squeeze().T)\n",
    "#         plt.colorbar(asd5)\n",
    "        \n",
    "        \n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
